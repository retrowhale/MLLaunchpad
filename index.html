<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Python Test Machine Learning Launchpad</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header */
        header {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 1rem 0;
            position: sticky;
            top: 0;
            z-index: 1000;
            border-bottom: 1px solid rgba(255, 255, 255, 0.2);
        }

        nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
        }

        .logo {
            font-size: 1.8rem;
            font-weight: bold;
            color: white;
            text-decoration: none;
        }

        .nav-links {
            display: flex;
            list-style: none;
            gap: 1rem; /* Adjusted gap for more links */
            flex-wrap: wrap;
            align-items: center;
        }

        .nav-links a {
            color: white;
            text-decoration: none;
            transition: color 0.3s ease;
            padding: 0.5rem 1rem;
            border-radius: 5px;
            cursor: pointer;
        }

        .nav-links a:hover, .nav-links a.active {
            background: rgba(255, 255, 255, 0.2);
            color: #fff;
        }

        /* Main Content */
        main {
            background: white;
            margin: 2rem 0;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .page {
            display: none;
            padding: 3rem;
            animation: fadeIn 0.5s ease-in;
        }

        .page.active {
            display: block;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        h1 {
            color: #2c3e50;
            font-size: 2.5rem;
            margin-bottom: 2rem;
            text-align: center;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        h2 {
            color: #34495e;
            font-size: 1.8rem;
            margin: 2rem 0 1rem 0;
            border-bottom: 2px solid #3498db;
            padding-bottom: 0.5rem;
        }

        h3 {
            color: #2c3e50;
            font-size: 1.4rem;
            margin: 1.5rem 0 1rem 0;
        }

        p {
            margin-bottom: 1rem;
            font-size: 1.1rem;
            line-height: 1.8;
        }

        /* Code Blocks */
        .code-block {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 1.5rem;
            border-radius: 8px;
            margin: 1rem 0;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            position: relative;
        }

        .code-block::before {
            content: 'Python';
            position: absolute;
            top: 0.5rem;
            right: 1rem;
            font-size: 0.8rem;
            color: #95a5a6;
        }
        
        pre {
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        /* Buttons */
        .cta-button {
            background: linear-gradient(45deg, #3498db, #2980b9);
            color: white;
            padding: 1rem 2rem;
            border: none;
            border-radius: 30px;
            font-size: 1.1rem;
            cursor: pointer;
            transition: all 0.3s ease;
            text-decoration: none;
            display: inline-block;
            margin: 1rem 0;
            box-shadow: 0 5px 15px rgba(52, 152, 219, 0.3);
        }

        .cta-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(52, 152, 219, 0.4);
        }

        /* Cards */
        .card-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin: 2rem 0;
        }

        .card {
            background: linear-gradient(135deg, #f8f9fa, #e9ecef);
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
            border-left: 4px solid #3498db;
        }

        .card:hover {
            transform: translateY(-5px);
        }

        .card h3 {
            color: #2c3e50;
            margin-bottom: 1rem;
        }

        /* Lists */
        ul {
            margin: 1rem 0;
            padding-left: 2rem;
        }

        li {
            margin-bottom: 0.5rem;
            font-size: 1.1rem;
        }

        /* Highlight boxes */
        .highlight-box {
            background: linear-gradient(135deg, #74b9ff, #0984e3);
            color: white;
            padding: 1.5rem;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: 0 5px 15px rgba(116, 185, 255, 0.3);
        }

        .warning-box {
            background: linear-gradient(135deg, #fdcb6e, #e17055);
            color: white;
            padding: 1.5rem;
            border-radius: 10px;
            margin: 1.5rem 0;
            box-shadow: 0 5px 15px rgba(253, 203, 110, 0.3);
        }

        /* Formula styling */
        .formula {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 5px;
            margin: 1rem 0;
            font-family: 'Times New Roman', serif;
            font-size: 1.2rem;
            text-align: center;
            border-left: 4px solid #e74c3c;
        }
        
        /* Modal Styles */
        .modal {
            display: none; /* Hidden by default */
            position: fixed; /* Stay in place */
            z-index: 2000; /* Sit on top */
            left: 0;
            top: 0;
            width: 100%; /* Full width */
            height: 100%; /* Full height */
            overflow: auto; /* Enable scroll if needed */
            background-color: rgba(0,0,0,0.6); /* Black w/ opacity */
            padding-top: 60px;
        }

        .modal-content {
            background-color: #fefefe;
            margin: 5% auto;
            padding: 30px;
            border: 1px solid #888;
            width: 80%;
            max-width: 400px;
            border-radius: 15px;
            position: relative;
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
            animation: fadeIn 0.3s;
        }

        .close-btn {
            color: #aaa;
            float: right;
            font-size: 28px;
            font-weight: bold;
            line-height: 1;
        }

        .close-btn:hover,
        .close-btn:focus {
            color: black;
            text-decoration: none;
            cursor: pointer;
        }

        /* Form Styles inside Modal */
        .modal-content h2 {
            text-align: center;
            margin-bottom: 1.5rem;
            border-bottom: none;
            font-size: 2rem;
            background: none;
            -webkit-text-fill-color: #2c3e50;
        }
        
        .modal-content form {
            display: flex;
            flex-direction: column;
        }

        .form-group {
            margin-bottom: 1rem;
        }

        .form-group label {
            display: block;
            margin-bottom: 0.5rem;
            color: #555;
        }

        .form-group input {
            width: 100%;
            padding: 0.8rem;
            border: 1px solid #ccc;
            border-radius: 5px;
            font-size: 1rem;
        }

        .modal-content .cta-button {
            width: 100%;
            margin-top: 1rem;
            margin-bottom: 0.5rem;
        }

        .secondary-button {
            background: #ecf0f1;
            color: #34495e;
            padding: 0.8rem 2rem;
            border: 1px solid #bdc3c7;
            border-radius: 30px;
            font-size: 1.1rem;
            cursor: pointer;
            transition: all 0.3s ease;
            text-decoration: none;
            display: inline-block;
            margin: 0.5rem 0 0 0;
            width: 100%;
        }

        .secondary-button:hover {
            background: #d5dbdb;
        }


        /* Responsive */
        @media (max-width: 992px) {
            .nav-links {
                gap: 0.5rem;
                justify-content: center;
                width: 100%;
                margin-top: 1rem;
            }
             .nav-links a {
                padding: 0.4rem 0.6rem;
                font-size: 0.9rem;
            }
        }
        @media (max-width: 768px) {
            h1 {
                font-size: 2rem;
            }
            .page {
                padding: 2rem 1rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <nav class="container">
            <a href="#" class="logo" onclick="showPage('home', this)">🚀 ML Test Launchpad</a>
            <ul class="nav-links">
                <li><a href="#" onclick="showPage('home', this)" class="active">Home</a></li>
                <li><a href="#" onclick="showPage('overview', this)">Overview</a></li>
                <li><a href="#" onclick="showPage('python-basics', this)">Python</a></li>
                <li><a href="#" onclick="showPage('libraries', this)">Libraries</a></li>
                <li><a href="#" onclick="showPage('data-prep', this)">Data Prep</a></li>
                <li><a href="#" onclick="showPage('regression', this)">Regression</a></li>
                <li><a href="#" onclick="showPage('regression-exercise', this)">Regression Ex.</a></li>
                <li><a href="#" onclick="showPage('decision-trees', this)">Trees</a></li>
                <li><a href="#" onclick="showPage('knn', this)">k-NN</a></li>
                <li><a href="#" onclick="showPage('lab-exercise', this)" style="background: #e74c3c; border-radius: 5px;">Exercise</a></li>
                <li><a href="#" id="login-btn">Login</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <!-- All page content remains the same -->
        <!-- Page 1: Homepage -->
        <div id="home" class="page active">
              <h1>Welcome to the Python Test Machine Learning Launchpad</h1>
            <div class="highlight-box">
                <h2>🎯 Your Journey Starts Here</h2>
                <p>Welcome to the exciting world of machine learning with Python! Whether you're a curious developer, aspiring data scientist, or someone who's always wondered how computers learn, you've come to the right place. This comprehensive launchpad will take you from Python fundamentals to building your first intelligent models.</p>
            </div>
            <h2>🌟 What You'll Learn</h2>
            <div class="card-grid">
                <div class="card"><h3>🐍 Python Mastery</h3><p>Go from Python basics to advanced data manipulation with essential libraries like NumPy, Pandas, and Matplotlib.</p></div>
                <div class="card"><h3>🧠 ML Foundations</h3><p>Understand the theory behind key algorithms and learn when to use each approach for different problems.</p></div>
                <div class="card"><h3>🔧 Hands-On Projects</h3><p>Build real machine learning models with step-by-step guidance and runnable code examples.</p></div>
                <div class="card"><h3>📊 Data Science Skills</h3><p>Learn data exploration, preprocessing, and visualization techniques used by professional data scientists.</p></div>
            </div>
            <h2>👥 Who Is This For?</h2>
            <p>This course is designed for aspiring data analysts, developers looking to add ML to their skillset, students exploring career opportunities, and curious minds who want to understand how intelligent systems work. We assume you have some basic programming knowledge but are new to the world of machine learning.</p>
            <h2>🗺️ Your Learning Path</h2>
            <p>Our website is carefully structured to guide you through a logical learning progression. You'll start with foundational concepts and Python essentials, then dive into data preparation and exploration, before finally building and understanding different types of machine learning algorithms. Each section builds upon the previous one, creating a solid foundation for your ML journey.</p>
            <div style="text-align: center; margin-top: 3rem;"><a href="#" onclick="showPage('overview', this)" class="cta-button">🚀 Start Your Learning Journey</a></div>
        </div>

        <!-- Page 2: Course & ML Overview -->
        <div id="overview" class="page">
            <h1>Getting Started: Course and Machine Learning Overview</h1>
            <h2>📚 Course Overview</h2>
            <p>This course is designed to provide you with a solid, practical foundation in machine learning using Python. You'll learn not just how to use ML algorithms, but understand the principles behind them, enabling you to make informed decisions about which approach to use for different problems.</p>
            <div class="highlight-box">
                <h3>🛤️ Learning Roadmap</h3>
                <p><strong>Foundation:</strong> Python Basics → Data Libraries → Data Preparation</p>
                <p><strong>Core ML:</strong> Supervised Learning (Regression, Classification) → Model Evaluation</p>
                <p><strong>Algorithms:</strong> Linear Regression → Decision Trees → k-Nearest Neighbors</p>
            </div>
            <h2>🤖 What is Machine Learning?</h2>
            <p>Machine learning is like teaching a computer to learn from experience, similar to how humans learn patterns and make decisions. Instead of programming explicit rules, we feed the computer data and let it discover patterns on its own. The core idea is that algorithms can automatically learn patterns from data to make predictions or decisions without being explicitly programmed for every scenario.</p>
            <h2>🎯 Types of Machine Learning</h2>
            <div class="card-grid">
                <div class="card"><h3>📖 Supervised Learning</h3><p><strong>Learning from labeled data</strong> - like a student learning with an answer key. Example: Predicting house prices based on historical data. Keywords: Labeled data, prediction, classification</p></div>
                <div class="card"><h3>🔍 Unsupervised Learning</h3><p><strong>Finding hidden patterns</strong> in unlabeled data - like a detective finding clues. Example: Grouping customers into different segments. Keywords: Unlabeled data, clustering, pattern discovery</p></div>
                <div class="card"><h3>🎮 Reinforcement Learning</h3><p><strong>Learning through trial and error</strong> - an agent learning by receiving rewards or penalties. Example: Training an AI to play a game. Keywords: Agent, environment, rewards, policy</p></div>
            </div>
        </div>

        <!-- Page 3: Python Programming Basics -->
        <div id="python-basics" class="page">
            <h1>Python Essentials for Machine Learning</h1>
            <h2>🐍 Why Python for Machine Learning?</h2>
            <p>Python's simplicity, readability, and extensive ecosystem of libraries make it the language of choice for ML.</p>
            <h2>📊 Data Types, Variables, and Control Flow</h2>
            <h3>Data Types and Variables</h3>
            <div class="code-block"><pre>age = 25              # Integer
height = 5.9          # Float
name = "Alice"        # String
is_student = True     # Boolean</pre></div>
            <h3>Control Flow</h3>
            <div class="code-block"><pre># If-elif-else
score = 85
if score >= 90: grade = "A"
elif score >= 80: grade = "B"
else: grade = "C"
print(f"Grade: {grade}")

# For loop
for i in range(3): print(f"Iteration {i}")</pre></div>
            <h2>🔧 Functions and Error Handling</h2>
            <h3>Functions</h3>
            <div class="code-block"><pre>def greet(name):
    return f"Hello, {name}!"
print(greet("World"))</pre></div>
            <h3>Error Handling</h3>
            <div class="code-block"><pre>try:
    result = 10 / 0
except ZeroDivisionError:
    print("Cannot divide by zero!")</pre></div>
        </div>

        <!-- Page 4: Python Analytic Libraries -->
        <div id="libraries" class="page">
            <h1>The Data Scientist's Toolkit: NumPy, Pandas, and Matplotlib</h1>
            <h2>🔢 NumPy: Numerical Python</h2>
            <p>NumPy is the foundation for numerical computing, providing fast and efficient array operations.</p>
            <div class="code-block"><pre>import numpy as np
arr = np.array([1, 2, 3])
print(arr * 2) # Output: [2 4 6]</pre></div>
            <h2>🐼 Pandas: Data Analysis Library</h2>
            <p>Pandas is your go-to library for data manipulation, introducing the powerful DataFrame.</p>
            <div class="code-block"><pre>import pandas as pd
data = {'Name': ['Alice', 'Bob'], 'Age': [25, 30]}
df = pd.DataFrame(data)
print(df.describe())</pre></div>
            <h2>📊 Matplotlib/Seaborn: Data Visualization</h2>
            <p>Visualization is crucial for understanding data. Matplotlib is the foundation, and Seaborn makes creating beautiful statistical plots easy.</p>
            <div class="code-block"><pre>import matplotlib.pyplot as plt
plt.plot([1, 2, 3], [1, 4, 9])
# In a real script, you would use plt.show() to display the plot.
</pre></div>
        </div>

        <!-- Page 5: Data Exploration and Preprocessing -->
        <div id="data-prep" class="page">
            <h1>Preparing Your Data for Machine Learning</h1>
            <h2>🧹 Data Cleaning</h2>
            <p>Real-world data is messy. We need to handle missing values and outliers.</p>
            <div class="code-block"><pre># Filling missing values
median_age = df['age'].median()
df['age'].fillna(median_age, inplace=True)</pre></div>
            <h2>🔪 Train/Test Split</h2>
            <div class="warning-box"><h3>🚨 Critical Step: Train/Test Split</h3><p>We must evaluate our model on data it has never seen before to see how it will perform in the real world.</p></div>
            <div class="code-block"><pre>from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</pre></div>
        </div>
        
        <!-- Page 6: Linear Regression -->
        <div id="regression" class="page">
            <h1>Error-Based Learning: Linear Regression</h1>
            <p>Regression models predict a continuous value (e.g., price). Linear Regression finds the "line of best fit" through the data.</p>
            <div class="code-block"><pre>from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, y_train)
predictions = model.predict(X_test)</pre></div>
            <h2>⚖️ Error Metrics for Regression</h2>
            <p>We measure error to see how good our model is. Common metrics include Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).</p>
            <div class="code-block"><pre>from sklearn.metrics import mean_squared_error
rmse = mean_squared_error(y_test, predictions, squared=False)
print(f"RMSE: {rmse:.2f}")</pre></div>
        </div>
        
        <!-- Basic Regression Exercise -->
        <div id="regression-exercise" class="page">
            <h1>Exercise: Predicting Scores with Linear Regression</h1>
            
            <h2>1. Goal</h2>
            <p>This exercise provides a simple, step-by-step introduction to linear regression. You will build a model that predicts a student's exam score based on the number of hours they studied. This is a classic example of "error-based" supervised learning.</p>
            
            <h2>2. The Problem</h2>
            <p>We have data on how many hours students studied and their corresponding exam scores. Our goal is to train a model that can predict the exam score for a new student, given the hours they plan to study.</p>

            <h2>3. Step-by-Step Procedure</h2>

            <h3>Step 1: Import Libraries</h3>
            <p>Start by importing the necessary libraries.</p>
            <div class="code-block"><pre>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error</pre></div>

            <h3>Step 2: Create and Visualize the Data</h3>
            <p>We'll create some simple, synthetic data and visualize it to see the relationship.</p>
            <div class="code-block"><pre># Create synthetic data
np.random.seed(0)
hours_studied = np.random.rand(50, 1) * 10
exam_score = 50 + 5 * hours_studied + np.random.randn(50, 1) * 5

# Create a DataFrame
df = pd.DataFrame({'Hours_Studied': hours_studied.flatten(), 'Exam_Score': exam_score.flatten()})

# Visualize the data
plt.figure(figsize=(8, 6))
plt.scatter(df['Hours_Studied'], df['Exam_Score'])
plt.title('Exam Score vs. Hours Studied')
plt.xlabel('Hours Studied')
plt.ylabel('Exam Score')
plt.grid(True)
# In a real script, use plt.show()
</pre></div>
            <p><strong>Question:</strong> Does there appear to be a relationship between hours studied and exam score?</p>

            <h3>Step 3: Define Features (X) and Target (y)</h3>
            <p>Separate the data into our input feature (X) and the value we want to predict (y).</p>
            <div class="code-block"><pre>X = df[['Hours_Studied']]
y = df['Exam_Score']</pre></div>

            <h3>Step 4: Split Data into Training and Testing Sets</h3>
            <p>We'll use 80% of the data for training our model and 20% for testing its performance.</p>
            <div class="code-block"><pre>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</pre></div>
            
            <h3>Step 5: Train the Linear Regression Model</h3>
            <p>Now, we create an instance of the `LinearRegression` model and fit it to our training data.</p>
            <div class="code-block"><pre>model = LinearRegression()
model.fit(X_train, y_train)
print("Model trained successfully!")</pre></div>

            <h3>Step 6: Make Predictions and Evaluate the Model</h3>
            <p>Let's use our trained model to make predictions on the test data and see how well it did.</p>
            <div class="code-block"><pre># Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate error metrics
mae = mean_absolute_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")</pre></div>

            <h3>Step 7: Visualize the Results</h3>
            <p>A great way to see our model's performance is to plot the "line of best fit" over the test data.</p>
            <div class="code-block"><pre>plt.figure(figsize=(8, 6))
plt.scatter(X_test, y_test, color='blue', label='Actual Scores')
plt.plot(X_test, y_pred, color='red', linewidth=2, label='Predicted Line')
plt.title('Model Prediction vs. Actual Data')
plt.xlabel('Hours Studied')
plt.ylabel('Exam Score')
plt.legend()
plt.grid(True)
# In a real script, use plt.show()
</pre></div>

            <h2>4. Interpretation and Questions</h2>
            <ul>
                <li><strong>The Regression Line:</strong> What does the red line in the final plot represent?</li>
                <li><strong>Model Error:</strong> The Mean Absolute Error (MAE) was calculated. In simple terms, what does this value tell you about the model's average prediction error? For example, if the MAE is 5, it means the model's predictions are, on average, off by 5 points.</li>
                <li><strong>Making a Prediction:</strong> If a new student studies for 7 hours, what score would our model predict? (You can use `model.predict([[7]])` to find out).</li>
            </ul>
        </div>
        
        <!-- Page 7: Decision Trees -->
        <div id="decision-trees" class="page">
            <h1>Information-Based Learning: Decision Trees</h1>
            <p>Decision Trees make predictions by learning a series of if-then-else questions, forming a tree-like structure. They are great for classification.</p>
            <h2>🍃 Entropy and Information Gain</h2>
            <p>The tree decides which question to ask by picking the one that provides the most "information gain"—the one that best splits the data into pure groups.</p>
            <div class="code-block"><pre>from sklearn.tree import DecisionTreeClassifier
tree_clf = DecisionTreeClassifier(max_depth=3)
tree_clf.fit(X, y)</pre></div>
        </div>
        
        <!-- Page 8: k-Nearest Neighbors (k-NN) -->
        <div id="knn" class="page">
            <h1>Similarity-Based Learning: k-Nearest Neighbors (k-NN)</h1>
            <p>k-NN classifies a new data point based on the majority class of its 'k' closest neighbors. It's simple and intuitive.</p>
            <div class="warning-box"><h3>🚨 The Importance of Feature Scaling</h3><p>k-NN relies on distance, so features with large ranges can dominate those with small ranges. It is <strong>critical</strong> to scale your data before applying k-NN.</p></div>
            <div class="code-block"><pre>from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)</pre></div>
        </div>
        
        <!-- Page 9: Lab Exercise (MODIFIED) -->
        <div id="lab-exercise" class="page">
             <h1>Lab Exercise: Predicting Customer Churn with k-NN</h1>

             <h2>1. Learning Goals</h2>
             <p>Welcome! In this lab, you'll apply your skills to a common business problem: predicting customer churn. By the end, you will be able to:</p>
             <ul>
                 <li>Create and inspect a realistic, synthetic dataset.</li>
                 <li>Perform essential data cleaning and preprocessing.</li>
                 <li>Implement, train, and evaluate a k-Nearest Neighbors (k-NN) classification model.</li>
                 <li>Interpret a confusion matrix and classification report to understand model performance.</li>
                 <li>Find the optimal value for 'k' to improve your model.</li>
             </ul>

             <h2>2. Background</h2>
             <p><strong>The Problem: Customer Churn.</strong> Customer churn is when a customer stops doing business with a company. Predicting which customers are likely to churn is a valuable task, as it allows a company to proactively offer incentives to keep them.</p>
             <p><strong>The Dataset.</strong> We will create a synthetic dataset of telecom customers. Our goal is to predict whether a customer will churn ('Yes' or 'No') based on features like their account tenure, monthly bill, and total charges.</p>

             <h2>3. Lab Procedure: Step-by-Step</h2>
             
             <h3>Step 1: Setup and Library Imports</h3>
             <p>First, import the necessary libraries for data science and machine learning.</p>
             <div class="code-block"><pre>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix</pre></div>

             <h3>Step 2: Create and Explore the Data</h3>
             <p>Instead of loading a file, we'll generate our own data. This gives us full control and understanding.</p>
             <div class="code-block"><pre># Generate synthetic customer data
np.random.seed(42)
n_samples = 500
tenure = np.random.randint(1, 73, n_samples)
monthly_charges = np.random.uniform(20, 120, n_samples)
total_charges = tenure * monthly_charges + np.random.normal(0, 100, n_samples)
churn = np.where( (tenure < 12) & (monthly_charges > 70), 1, 
                  np.where( (tenure < 24) & (monthly_charges > 50), np.random.choice([0,1], p=[0.7, 0.3]), 0) )

df = pd.DataFrame({
    'tenure': tenure,
    'monthly_charges': monthly_charges,
    'total_charges': total_charges,
    'churn': churn
})

# Introduce some missing values to make it realistic
df.loc[df.sample(frac=0.05).index, 'total_charges'] = np.nan

print("Data Head:")
print(df.head())
print("\nData Info:")
df.info()</pre></div>
             <p><strong>Question:</strong> What do you notice about the data types? How many missing values are there in `total_charges`?</p>

             <h3>Step 3: Data Preprocessing and Cleaning</h3>
             <p>Real-world data is often messy. Let's fill the missing `total_charges` with the median value of the column.</p>
             <div class="code-block"><pre># Fill missing values
median_total_charges = df['total_charges'].median()
df['total_charges'].fillna(median_total_charges, inplace=True)

print("\nMissing values after cleaning:")
print(df.isnull().sum())</pre></div>

             <h3>Step 4: Define Features (X) and Target (y)</h3>
             <p>Separate the data into features (the inputs) and the target (what we want to predict).</p>
             <div class="code-block"><pre>X = df[['tenure', 'monthly_charges', 'total_charges']]
y = df['churn']</pre></div>

             <h3>Step 5: Split Data and Scale Features</h3>
             <p>Split the data into training and testing sets, then apply feature scaling—a critical step for k-NN.</p>
             <div class="code-block"><pre># Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Data split and scaled successfully.")</pre></div>

             <h3>Step 6: Train the k-NN Model</h3>
             <p>Now, train the k-NN classifier on the scaled training data. We'll start with k=7.</p>
             <div class="code-block"><pre># Train the model
knn = KNeighborsClassifier(n_neighbors=7)
knn.fit(X_train_scaled, y_train)

print("k-NN model trained with k=7.")</pre></div>

             <h3>Step 7: Evaluate the Model</h3>
             <p>Make predictions on the unseen test data and evaluate the model's performance.</p>
             <div class="code-block"><pre># Make predictions
y_pred = knn.predict(X_test_scaled)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.4f}\n")

# Display the classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))

# Display the confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
# In a real script, use plt.show() to display
</pre></div>
             
             <h2>4. Model Performance Analysis</h2>
             <p>Evaluating a classification model goes beyond simple accuracy. We need to understand the types of errors it makes and how well it identifies the classes we care about most.</p>
             <ul>
                 <li><strong>Overall Correctness:</strong> What is the model's accuracy? Why might this single number not tell the whole story, especially if one group (e.g., non-churners) is much larger than the other?</li>
                 <li><strong>Detailed Performance Metrics:</strong> Examine the classification report. What do the precision and recall scores for the "Churn" class suggest about the model's effectiveness in identifying at-risk customers?</li>
                 <li><strong>Error Analysis:</strong> Look at the confusion matrix. How many actual churners did the model correctly identify (True Positives)? How many non-churners did it incorrectly flag as potential churners (False Positives)?</li>
             </ul>

             <h2>5. Hyperparameter Tuning</h2>
             <p>The performance of many machine learning models is sensitive to their configuration settings, known as hyperparameters. For k-NN, the most important hyperparameter is 'k' itself. We can find a better value for 'k' by systematically testing a range of options.</p>
             <div class="code-block"><pre>k_range = range(1, 26)
accuracies = []

for k in k_range:
    knn_loop = KNeighborsClassifier(n_neighbors=k)
    knn_loop.fit(X_train_scaled, y_train)
    y_pred_loop = knn_loop.predict(X_test_scaled)
    accuracies.append(accuracy_score(y_test, y_pred_loop))

# Plot the results
plt.figure(figsize=(12, 6))
plt.plot(k_range, accuracies, marker='o', linestyle='dashed')
plt.title('Model Accuracy vs. K Value')
plt.xlabel('K Value')
plt.ylabel('Accuracy')
plt.xticks(k_range)
plt.grid(True)
# In a real script, use plt.show() to display
</pre></div>
             <p><strong>Challenge:</strong> By observing the generated plot, what value of 'k' provides the highest accuracy? How does the model's performance change as 'k' varies?</p>

        </div>

    </main>

    <!-- The Modal -->
    <div id="login-modal" class="modal">
      <!-- Modal content -->
      <div class="modal-content">
        <span class="close-btn">&times;</span>
        <h2>Login</h2>
        <form onsubmit="event.preventDefault();">
          <div class="form-group">
            <label for="email">Email</label>
            <input type="email" id="email" name="email" placeholder="you@example.com" required>
          </div>
          <div class="form-group">
            <label for="password">Password</label>
            <input type="password" id="password" name="password" placeholder="••••••••" required>
          </div>
          <button type="submit" class="cta-button">Login</button>
          <button type="button" class="secondary-button" id="signup-btn">Sign Up</button>
        </form>
      </div>
    </div>

    <script>
        // Modal Logic
        const loginModal = document.getElementById('login-modal');
        const loginBtn = document.getElementById('login-btn');
        const closeBtn = document.querySelector('.close-btn');

        // Show modal when login button is clicked
        if (loginBtn) {
            loginBtn.onclick = function() {
                loginModal.style.display = "block";
            }
        }

        // Hide modal when close button is clicked
        if (closeBtn) {
            closeBtn.onclick = function() {
                loginModal.style.display = "none";
            }
        }

        // Hide modal when user clicks outside of it
        window.onclick = function(event) {
            if (event.target == loginModal) {
                loginModal.style.display = "none";
            }
        }
        
        // Page switching logic
        function showPage(pageId, element) {
            // Hide all pages
            const pages = document.querySelectorAll('.page');
            pages.forEach(page => {
                page.classList.remove('active');
            });

            // Show the selected page
            const activePage = document.getElementById(pageId);
            if (activePage) {
                activePage.classList.add('active');
            }
            
            // Update active link in navigation
            const navLinks = document.querySelectorAll('.nav-links a');
            navLinks.forEach(link => {
                link.classList.remove('active');
            });
            
            // Find the correct link to activate
            const correspondingLink = document.querySelector(`.nav-links a[onclick*="'${pageId}'"]`);
            if (correspondingLink) {
                correspondingLink.classList.add('active');
            } else if (element) {
                element.classList.add('active');
            }


            // Scroll to the top of the main content area
            window.scrollTo({
                top: document.querySelector('main').offsetTop - 80, // Adjust for sticky header
                behavior: 'smooth'
            });
        }
    </script>
</body>
</html>
